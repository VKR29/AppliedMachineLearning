{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQNbKsXG7U2u"
      },
      "source": [
        "# SMS Spam Classification - Data Preparation\n",
        "This notebook contains functions to load, preprocess, and split the SMS spam dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FmLnmUdA7U2w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB3ExH2A7U2w"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8hC8JcFr7U2w"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load SMS spam collection data from file.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    file_path : str\n",
        "        Path to the SMS spam collection file\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        DataFrame with columns 'label' and 'message'\n",
        "    \"\"\"\n",
        "    # Read tab-separated file\n",
        "    df = pd.read_csv(file_path, sep='\\t', names=['label', 'message'], encoding='utf-8')\n",
        "\n",
        "    print(f\"Data loaded successfully!\")\n",
        "    print(f\"Total samples: {len(df)}\")\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    print(df['label'].value_counts())\n",
        "    print(f\"\\nSample data:\")\n",
        "    print(df.head())\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTkl6gs97U2w"
      },
      "source": [
        "## 2. Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gkH7hxTe7U2w"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the SMS data.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Raw dataframe with 'label' and 'message' columns\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame\n",
        "        Preprocessed dataframe\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Convert labels to binary (0 = ham, 1 = spam)\n",
        "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates(subset='message', keep='first')\n",
        "\n",
        "    # Remove null values if any\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Reset index\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    print(f\"Preprocessing complete!\")\n",
        "    print(f\"Total samples after preprocessing: {len(df)}\")\n",
        "    print(f\"\\nClass distribution:\")\n",
        "    print(df['label'].value_counts())\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYspbxYn7U2x"
      },
      "source": [
        "## 3. Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MtWcwCmB7U2x"
      },
      "outputs": [],
      "source": [
        "def split_data(df, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
        "    \"\"\"\n",
        "    Split data into train, validation, and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pd.DataFrame\n",
        "        Preprocessed dataframe\n",
        "    train_size : float\n",
        "        Proportion of data for training (default: 0.7)\n",
        "    val_size : float\n",
        "        Proportion of data for validation (default: 0.15)\n",
        "    test_size : float\n",
        "        Proportion of data for testing (default: 0.15)\n",
        "    random_state : int\n",
        "        Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple\n",
        "        (train_df, val_df, test_df)\n",
        "    \"\"\"\n",
        "    assert abs(train_size + val_size + test_size - 1.0) < 1e-6, \"Sizes must sum to 1.0\"\n",
        "\n",
        "    # First split: separate test set\n",
        "    train_val_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    # Second split: separate train and validation\n",
        "    val_ratio = val_size / (train_size + val_size)\n",
        "    train_df, val_df = train_test_split(\n",
        "        train_val_df,\n",
        "        test_size=val_ratio,\n",
        "        random_state=random_state,\n",
        "        stratify=train_val_df['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Data split complete!\")\n",
        "    print(f\"\\nTrain set: {len(train_df)} samples\")\n",
        "    print(train_df['label'].value_counts())\n",
        "    print(f\"\\nValidation set: {len(val_df)} samples\")\n",
        "    print(val_df['label'].value_counts())\n",
        "    print(f\"\\nTest set: {len(test_df)} samples\")\n",
        "    print(test_df['label'].value_counts())\n",
        "\n",
        "    return train_df, val_df, test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSg_p7kD7U2x"
      },
      "source": [
        "## 4. Store Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QuBaYrYQ7U2x"
      },
      "outputs": [],
      "source": [
        "def store_splits(train_df, val_df, test_df,\n",
        "                 train_path='train.csv',\n",
        "                 val_path='validation.csv',\n",
        "                 test_path='test.csv'):\n",
        "    \"\"\"\n",
        "    Store train, validation, and test splits to CSV files.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    train_df, val_df, test_df : pd.DataFrame\n",
        "        DataFrames to store\n",
        "    train_path, val_path, test_path : str\n",
        "        File paths for storing the splits\n",
        "    \"\"\"\n",
        "    train_df.to_csv(train_path, index=False)\n",
        "    val_df.to_csv(val_path, index=False)\n",
        "    test_df.to_csv(test_path, index=False)\n",
        "\n",
        "    print(f\"Splits saved successfully!\")\n",
        "    print(f\"  - Train: {train_path}\")\n",
        "    print(f\"  - Validation: {val_path}\")\n",
        "    print(f\"  - Test: {test_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfoIoIrv7U2x"
      },
      "source": [
        "## 5. Run Complete Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCCpG6rm7U2x",
        "outputId": "005678ff-7a5e-499a-9b86-9a57f5f9ff02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n",
            "Total samples: 5572\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample data:\n",
            "  label                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "Preprocessing complete!\n",
            "Total samples after preprocessing: 5169\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "0    4516\n",
            "1     653\n",
            "Name: count, dtype: int64\n",
            "Data split complete!\n",
            "\n",
            "Train set: 3617 samples\n",
            "label\n",
            "0    3160\n",
            "1     457\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation set: 776 samples\n",
            "label\n",
            "0    678\n",
            "1     98\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test set: 776 samples\n",
            "label\n",
            "0    678\n",
            "1     98\n",
            "Name: count, dtype: int64\n",
            "Splits saved successfully!\n",
            "  - Train: train.csv\n",
            "  - Validation: validation.csv\n",
            "  - Test: test.csv\n",
            "\n",
            "==================================================\n",
            "Data preparation complete! Ready for training.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load data\n",
        "    df = load_data('SMSSpamCollection')\n",
        "\n",
        "    # Preprocess data\n",
        "    df_processed = preprocess_data(df)\n",
        "\n",
        "    # Split data\n",
        "    train_df, val_df, test_df = split_data(df_processed)\n",
        "\n",
        "    # Store splits\n",
        "    store_splits(train_df, val_df, test_df)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Data preparation complete! Ready for training.\")\n",
        "    print(\"=\"*50)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
